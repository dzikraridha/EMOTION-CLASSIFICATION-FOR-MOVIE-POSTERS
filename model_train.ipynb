{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dzikraridha/movie-poster-emotion/blob/main/model_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMxBiaorOhNk",
        "outputId": "f0fcecbb-fc8a-406d-b6c3-10b08ddefec1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', timeout_ms=300000) # Increased timeout to 5 minutes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXnddUzs6P2j"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "p8Nth82h5xMs",
        "outputId": "2aa34263-90ed-4c08-814d-d2f39291ffa2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   imdbId                       Genre                               Title  \\\n",
              "0  114709  Animation|Adventure|Comedy                    Toy Story (1995)   \n",
              "1  113497     Action|Adventure|Family                      Jumanji (1995)   \n",
              "2  114885        Comedy|Drama|Romance            Waiting to Exhale (1995)   \n",
              "3  113041       Comedy|Family|Romance  Father of the Bride Part II (1995)   \n",
              "4  113277          Action|Crime|Drama                         Heat (1995)   \n",
              "\n",
              "                                 Image_Paths  \\\n",
              "0  /content/drive/MyDrive/Posters/114709.jpg   \n",
              "1  /content/drive/MyDrive/Posters/113497.jpg   \n",
              "2  /content/drive/MyDrive/Posters/114885.jpg   \n",
              "3  /content/drive/MyDrive/Posters/113041.jpg   \n",
              "4  /content/drive/MyDrive/Posters/113277.jpg   \n",
              "\n",
              "                                             emotion  \n",
              "0                      ['Happy', 'Surprised', 'Sad']  \n",
              "1  ['Fear', 'Sad', 'Angry', 'Neutral', 'Happy', '...  \n",
              "2             ['Happy', 'Angry', 'Surprised', 'Sad']  \n",
              "3           ['Happy', 'Neutral', 'Surprised', 'Sad']  \n",
              "4   ['Fear', 'Sad', 'Disgust', 'Angry', 'Surprised']  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5ca27123-94c8-40d1-8e8f-34dbb7091b0c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>imdbId</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Title</th>\n",
              "      <th>Image_Paths</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>114709</td>\n",
              "      <td>Animation|Adventure|Comedy</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>/content/drive/MyDrive/Posters/114709.jpg</td>\n",
              "      <td>['Happy', 'Surprised', 'Sad']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>113497</td>\n",
              "      <td>Action|Adventure|Family</td>\n",
              "      <td>Jumanji (1995)</td>\n",
              "      <td>/content/drive/MyDrive/Posters/113497.jpg</td>\n",
              "      <td>['Fear', 'Sad', 'Angry', 'Neutral', 'Happy', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>114885</td>\n",
              "      <td>Comedy|Drama|Romance</td>\n",
              "      <td>Waiting to Exhale (1995)</td>\n",
              "      <td>/content/drive/MyDrive/Posters/114885.jpg</td>\n",
              "      <td>['Happy', 'Angry', 'Surprised', 'Sad']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>113041</td>\n",
              "      <td>Comedy|Family|Romance</td>\n",
              "      <td>Father of the Bride Part II (1995)</td>\n",
              "      <td>/content/drive/MyDrive/Posters/113041.jpg</td>\n",
              "      <td>['Happy', 'Neutral', 'Surprised', 'Sad']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>113277</td>\n",
              "      <td>Action|Crime|Drama</td>\n",
              "      <td>Heat (1995)</td>\n",
              "      <td>/content/drive/MyDrive/Posters/113277.jpg</td>\n",
              "      <td>['Fear', 'Sad', 'Disgust', 'Angry', 'Surprised']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ca27123-94c8-40d1-8e8f-34dbb7091b0c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5ca27123-94c8-40d1-8e8f-34dbb7091b0c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5ca27123-94c8-40d1-8e8f-34dbb7091b0c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d2df0d7b-194d-49b2-8c18-36e4ba17d4d3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d2df0d7b-194d-49b2-8c18-36e4ba17d4d3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d2df0d7b-194d-49b2-8c18-36e4ba17d4d3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 33944,\n  \"fields\": [\n    {\n      \"column\": \"imdbId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1194769,\n        \"min\": 3,\n        \"max\": 6098922,\n        \"num_unique_values\": 33944,\n        \"samples\": [\n          1217578,\n          74157,\n          1539313\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Genre\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1214,\n        \"samples\": [\n          \"Documentary|Crime|News\",\n          \"Documentary|Drama|News\",\n          \"Comedy|Thriller\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 33911,\n        \"samples\": [\n          \"I Saw Mommy Kissing Santa Claus (2002)\",\n          \"Gold Diggers of 1933 (1933)\",\n          \"Murder in Greenwich (2002)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Image_Paths\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 33944,\n        \"samples\": [\n          \"/content/drive/MyDrive/Posters/1217578.jpg\",\n          \"/content/drive/MyDrive/Posters/74157.jpg\",\n          \"/content/drive/MyDrive/Posters/1539313.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emotion\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 81,\n        \"samples\": [\n          \"['Neutral', 'Angry', 'Disgust']\",\n          \"['Happy', 'Surprised', 'Sad']\",\n          \"['Happy', 'Fear', 'Surprised', 'Sad']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/MovieGenreEmotion_clean.csv\", encoding='ISO-8859-1')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXw0Au3pqcKG",
        "outputId": "8d9714bd-c431-4410-db58-cb1acef05857"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.17.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.12.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.69.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow keras pandas numpy matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AF5bcGIzl0vI",
        "outputId": "cec0d463-ee60-4dde-878d-6661988bf0ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.17.1)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.12.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.69.0)\n",
            "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
            "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.4/615.4 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboard, tensorflow\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.1\n",
            "    Uninstalling tensorflow-2.17.1:\n",
            "      Successfully uninstalled tensorflow-2.17.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.18.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tensorboard-2.18.0 tensorflow-2.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbeBsjQO9lZj",
        "outputId": "3727456a-2618-466b-e725-1f4bc8e4b855"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/Posters/197154.jpg', '/content/drive/MyDrive/Posters/55995.jpg', '/content/drive/MyDrive/Posters/1975179.jpg', '/content/drive/MyDrive/Posters/1942798.jpg', '/content/drive/MyDrive/Posters/4063438.jpg']\n"
          ]
        }
      ],
      "source": [
        "# Path to the folder where images are stored\n",
        "image_folder = '/content/drive/MyDrive/Posters'\n",
        "\n",
        "# Get the list of all image files in the folder\n",
        "image_paths = [os.path.join(image_folder, img) for img in os.listdir(image_folder) if img.endswith('.jpg')]\n",
        "\n",
        "# Display the first few image paths\n",
        "print(image_paths[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nITsuPBWCZmt"
      },
      "outputs": [],
      "source": [
        "# Create list of all emotions\n",
        "emotions = ['Fear', 'Disgust', 'Surprised', 'Neutral', 'Happy', 'Sad', 'Angry']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6i04zijRCYWs"
      },
      "outputs": [],
      "source": [
        "emotion_to_index = {emotion: idx for idx, emotion in enumerate(emotions)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIoOcF5XGaVr"
      },
      "outputs": [],
      "source": [
        "df_sampled = df.sample(n=6800, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b02d3HK9UnnD"
      },
      "outputs": [],
      "source": [
        "genres_to_emotion = {\n",
        "    'Action': ['Surprised', 'Fear', 'Angry'],\n",
        "    'Adventure': ['Surprised', 'Happy'],\n",
        "    'Animation': ['Happy', 'Surprised', 'Sad'],\n",
        "    'Biography': ['Sad', 'Angry', 'Neutral'],\n",
        "    'Comedy': ['Happy', 'Surprised'],\n",
        "    'Crime': ['Angry', 'Fear', 'Disgust'],\n",
        "    'Documentary': ['Neutral','Angry', 'Disgust'],\n",
        "    'Drama': ['Sad', 'Angry'],\n",
        "    'Family': ['Happy', 'Sad', 'Neutral'],\n",
        "    'Fantasy': ['Surprised', 'Happy', 'Fear'],\n",
        "    'History': ['Sad', 'Angry'],\n",
        "    'Horror': ['Fear', 'Disgust'],\n",
        "    'Music': ['Happy', 'Neutral'],\n",
        "    'Mystery': ['Surprised', 'Fear'],\n",
        "    'Romance': ['Happy', 'Sad'],\n",
        "    'Sci-Fi': ['Surprised', 'Fear', 'Disgust'],\n",
        "    'Sport': ['Happy', 'Surprised'],\n",
        "    'Thriller': ['Fear', 'Surprised'],\n",
        "    'War': ['Sad', 'Angry']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converts movie genres into a multi-hot encoded emotion vector.\n",
        "def genres_to_emotions(genres):\n",
        "    genres_list = genres.split('|') if pd.notnull(genres) else []\n",
        "    emotion_vector = [0] * len(emotions)\n",
        "\n",
        "    for genre in genres_list:\n",
        "        # Skip invalid or empty genres\n",
        "        if genre in genres_to_emotion:\n",
        "            for emotion in genres_to_emotion[genre]:\n",
        "                emotion_index = emotions.index(emotion)\n",
        "                emotion_vector[emotion_index] = 1\n",
        "\n",
        "    return emotion_vector\n",
        "\n",
        "# Preprocessing Step\n",
        "valid_genres = set(genres_to_emotion.keys())\n",
        "\n",
        "def filter_valid_genres(row):\n",
        "    genres = row['Genre'].split('|') if pd.notnull(row['Genre']) else []\n",
        "    return all(genre in valid_genres for genre in genres)\n",
        "\n",
        "df_sampled = df_sampled[df_sampled.apply(filter_valid_genres, axis=1)]\n",
        "df_sampled['emotion'] = df_sampled['Genre'].apply(genres_to_emotions)"
      ],
      "metadata": {
        "id": "PjIncG6Dpcm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqx5WS2Pjof2",
        "outputId": "8c47ba7e-2d4a-4d1e-9201-23dfb5d92a87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The 'emotion' column is likely multi-hot encoded.\n"
          ]
        }
      ],
      "source": [
        "#Checks if the 'emotion' column in a DataFrame is multi-hot encoded based on the 'genres_to_emotion' mapping.\n",
        "\n",
        "def is_emotion_multi_hot_encoded(df):\n",
        "\n",
        "    # Check if the 'emotion' column exists and contains lists\n",
        "    if 'emotion' in df.columns and all(isinstance(item, list) for item in df['emotion']):\n",
        "        # Check if any movie has multiple emotions (more than one '1' in the list)\n",
        "        has_multiple_emotions = any(sum(item) > 1 for item in df['emotion'])\n",
        "        return has_multiple_emotions\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "# Check if 'emotion' column is multi-hot encoded\n",
        "if is_emotion_multi_hot_encoded(df_sampled):\n",
        "    print(\"The 'emotion' column is likely multi-hot encoded.\")\n",
        "else:\n",
        "    print(\"The 'emotion' column is not multi-hot encoded.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_sampled[['Genre', 'emotion']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tmXCvN4F3M5",
        "outputId": "9a4b96cc-2cbd-4270-ace5-654a2f51a1ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   Genre                emotion\n",
            "28892              Drama  [0, 0, 0, 0, 0, 1, 1]\n",
            "3776   Adventure|Fantasy  [1, 0, 1, 0, 1, 0, 0]\n",
            "23339             Sci-Fi  [1, 1, 1, 0, 0, 0, 0]\n",
            "7266              Comedy  [0, 0, 1, 0, 1, 0, 0]\n",
            "13416      Drama|Fantasy  [1, 0, 1, 0, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = {}\n",
        "for i, emotion in enumerate(emotions):\n",
        "    # Accessing the i-th emotion using a list comprehension\n",
        "    emotion_values = [row[i] for row in df_sampled['emotion'].to_list()]\n",
        "    class_weights[i] = class_weight.compute_class_weight(\n",
        "        'balanced',\n",
        "        classes=np.unique(emotion_values),\n",
        "        y=emotion_values\n",
        "    )"
      ],
      "metadata": {
        "id": "-UQdR9N6AkhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_emotions = np.concatenate(df_sampled['emotion'].to_list())\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.unique(all_emotions),  # Use all unique emotion values (0 and 1)\n",
        "    y=all_emotions  # Use all emotion occurrences\n",
        ")"
      ],
      "metadata": {
        "id": "TIAJiJH744ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAdwDbj3UDtq"
      },
      "outputs": [],
      "source": [
        "assert df_sampled['emotion'].apply(lambda x: sum(x) > 0).all(), \"Some movies have no emotions assigned!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqanoQ8Dj7yW",
        "outputId": "3f390f55-b92a-4aeb-937f-ecd2861fdeec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Genres: Animation|Adventure|Comedy\n",
            "Multi-hot encoded emotions: [0, 0, 1, 0, 1, 1, 0]\n",
            "Emotions: ['Fear', 'Disgust', 'Surprised', 'Neutral', 'Happy', 'Sad', 'Angry']\n"
          ]
        }
      ],
      "source": [
        "# Sample test input\n",
        "sample_genres = \"Animation|Adventure|Comedy\"\n",
        "\n",
        "# Get the multi-hot encoded emotion vector\n",
        "multi_hot_vector = genres_to_emotions(sample_genres)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Genres: {sample_genres}\")\n",
        "print(f\"Multi-hot encoded emotions: {multi_hot_vector}\")\n",
        "print(f\"Emotions: {emotions}\")  # To map the indices to actual emotions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUSL84nsd4ti"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "img_size = (224, 224)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPJFX4MFe6dn"
      },
      "outputs": [],
      "source": [
        "# Flatten the emotion lists to get all emotion occurrences\n",
        "all_emotions = np.concatenate(df_sampled['emotion'].to_list())\n",
        "\n",
        "# Calculate class weights for each emotion\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.unique(all_emotions),  # Use all unique emotion values (0 and 1)\n",
        "    y=all_emotions  # Use all emotion occurrences\n",
        ")\n",
        "\n",
        "# Create a dictionary mapping emotion index to class weight\n",
        "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "# Assume class_weights has weights for 0 and 1, representing absence and presence of emotions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "ME2uNv5jOh_Q",
        "outputId": "32c1ac26-2e18-4ac2-a3ec-ed7aa2eddd59"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def plot_emotion_distribution(df, genres_to_emotion, emotions):\n",
        "    emotion_counts = {emotion: 0 for emotion in emotions}\n",
        "\n",
        "    # Iterate through movie rows to collect emotion counts\n",
        "    for _, row in df.iterrows():\n",
        "        emotions_for_movie = genres_to_emotions(row['Genre'])  # Get emotions for the movie\n",
        "        if emotions_for_movie is not None:  # Skip movies with unmapped genres\n",
        "            for i, emotion_present in enumerate(emotions_for_movie):\n",
        "                if emotion_present:  # Increment count if emotion is present (1)\n",
        "                    emotion_counts[emotions[i]] += 1\n",
        "\n",
        "    plt.figure(figsize=(10, 6))  # Set figure size for better readability\n",
        "    plt.bar(emotion_counts.keys(), emotion_counts.values())\n",
        "    plt.title(\"Emotion Distribution\")\n",
        "    plt.xlabel(\"Emotions\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for clarity\n",
        "    plt.tight_layout()  # Adjust layout to prevent labels from overlapping\n",
        "    plt.show()\n",
        "\n",
        "plot_emotion_distribution(df_sampled, genres_to_emotions, emotions)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataGeneratorWithEmotions(Sequence):\n",
        "    def __init__(self, image_folder, df_sampled, batch_size, img_size, emotions, shuffle=True, augment=False, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.image_folder = image_folder\n",
        "        self.df_sampled = df_sampled\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.emotions = emotions\n",
        "        self.shuffle = shuffle\n",
        "        self.augment = augment\n",
        "        self.indexes = np.arange(len(self.df_sampled))\n",
        "\n",
        "        # Initialize augmentation generator\n",
        "        self.datagen = ImageDataGenerator(\n",
        "            rotation_range=20,\n",
        "            width_shift_range=0.2,\n",
        "            height_shift_range=0.2,\n",
        "            shear_range=0.2,\n",
        "            zoom_range=0.2,\n",
        "            horizontal_flip=True,\n",
        "            fill_mode='nearest'\n",
        "        ) if self.augment else None\n",
        "\n",
        "        # Initialize index array\n",
        "        self.indexes = np.arange(len(self.df_sampled))\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        # Number of batches per epoch\n",
        "        return int(np.ceil(len(self.df_sampled) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Get batch indexes\n",
        "        start_index = index * self.batch_size\n",
        "        end_index = min((index + 1) * self.batch_size, len(self.df_sampled))\n",
        "        batch_indexes = self.indexes[start_index:end_index]\n",
        "\n",
        "        # Get batch data\n",
        "        batch_filenames = self.df_sampled.iloc[batch_indexes]['imdbId'].values\n",
        "        batch_genres = self.df_sampled.iloc[batch_indexes]['Genre'].values\n",
        "\n",
        "        # Initialize arrays\n",
        "        batch_size_actual = len(batch_filenames)\n",
        "        images = np.zeros((batch_size_actual, *self.img_size, 3), dtype=np.float32)\n",
        "        emotion_labels = np.zeros((batch_size_actual, len(self.emotions)), dtype=np.float32)\n",
        "\n",
        "        # Load and preprocess each image\n",
        "        for i, (imdbId, genres) in enumerate(zip(batch_filenames, batch_genres)):\n",
        "            img_path = os.path.join(self.image_folder, f\"{imdbId}.jpg\")\n",
        "            try:\n",
        "                img = load_img(img_path, target_size=self.img_size)\n",
        "                img_array = img_to_array(img)\n",
        "                if self.augment and self.datagen:\n",
        "                    img_array = self.datagen.random_transform(img_array)\n",
        "                img_array = preprocess_input(img_array)\n",
        "                images[i] = img_array\n",
        "                emotion_labels[i] = genres_to_emotions(genres)  # Reuse the function\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading image {img_path}: {e}\")\n",
        "\n",
        "        return images, emotion_labels\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        # Shuffle the dataset at the end of each epoch\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n"
      ],
      "metadata": {
        "id": "OGPYqyh_ZTNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and test the generator\n",
        "generator = ImageDataGeneratorWithEmotions(\n",
        "    image_folder=image_folder,\n",
        "    df_sampled=df_sampled,\n",
        "    batch_size=32,\n",
        "    img_size=(224, 224),\n",
        "    emotions=emotions,\n",
        "    shuffle=True,\n",
        "    augment=True\n",
        ")\n",
        "\n",
        "sample_images, sample_labels = next(iter(generator))\n",
        "print(\"Sample Labels from Generator:\", sample_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNASus24p9LJ",
        "outputId": "46d43257-d2a6-40c9-8e4c-687ea71c327c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Labels from Generator: [[0. 0. 1. 0. 1. 1. 1.]\n",
            " [0. 0. 1. 1. 1. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 1. 1.]\n",
            " [0. 0. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 1. 0. 1. 0. 0.]\n",
            " [1. 1. 1. 0. 0. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 1. 1.]\n",
            " [1. 0. 1. 0. 1. 1. 1.]\n",
            " [0. 0. 1. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 1.]\n",
            " [0. 0. 1. 0. 1. 1. 1.]\n",
            " [1. 1. 1. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 0. 0. 1. 1.]\n",
            " [1. 0. 1. 0. 1. 1. 0.]\n",
            " [1. 1. 1. 0. 1. 0. 0.]\n",
            " [1. 1. 1. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1. 1.]\n",
            " [0. 0. 1. 0. 1. 0. 0.]\n",
            " [1. 0. 1. 0. 1. 0. 1.]\n",
            " [0. 0. 1. 1. 1. 1. 1.]\n",
            " [1. 0. 1. 0. 1. 1. 1.]\n",
            " [1. 1. 1. 0. 0. 1. 1.]\n",
            " [1. 1. 1. 0. 0. 1. 1.]\n",
            " [0. 0. 1. 0. 1. 1. 1.]\n",
            " [0. 0. 1. 0. 1. 1. 0.]\n",
            " [0. 0. 1. 0. 1. 1. 1.]\n",
            " [0. 0. 1. 0. 1. 1. 1.]\n",
            " [0. 0. 1. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 1. 1.]\n",
            " [1. 0. 1. 1. 0. 1. 1.]\n",
            " [1. 0. 1. 0. 0. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 1. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pv42HwLKCnBc",
        "outputId": "ea63e969-d900-4399-b010-6feff66b9b20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data: 5050 samples\n",
            "Validation data: 1263 samples\n"
          ]
        }
      ],
      "source": [
        "# Define valid genres\n",
        "valid_genres = set(genres_to_emotion.keys())\n",
        "\n",
        "# Filter the dataset to include only rows with valid genres\n",
        "def has_valid_genres(row):\n",
        "    genres = row['Genre'].split('|') if pd.notnull(row['Genre']) else []\n",
        "    return all(genre in valid_genres for genre in genres)\n",
        "\n",
        "df_sampled = df_sampled[df_sampled.apply(has_valid_genres, axis=1)]\n",
        "\n",
        "# Split the filtered data into 80% training and 20% validation\n",
        "train_data, val_data = train_test_split(df_sampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Check the size of each portion\n",
        "print(f\"Training data: {len(train_data)} samples\")\n",
        "print(f\"Validation data: {len(val_data)} samples\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPyru6ipKHWu"
      },
      "outputs": [],
      "source": [
        "# Create the training data generator\n",
        "train_generator = ImageDataGeneratorWithEmotions(\n",
        "    image_folder=image_folder,  # Path to images directory\n",
        "    df_sampled=train_data,  # Training dataset\n",
        "    batch_size=32,  # Batch size\n",
        "    img_size=(224, 224),  # Image size\n",
        "    emotions=emotions,  # Emotions to predict\n",
        "    shuffle=True,  # Shuffle the training data\n",
        "    augment=True  # Enable data augmentation\n",
        ")\n",
        "\n",
        "# Create the validation data generator\n",
        "val_generator = ImageDataGeneratorWithEmotions(\n",
        "    image_folder=image_folder,  # Path to images directory\n",
        "    df_sampled=val_data,  # Validation dataset\n",
        "    batch_size=32,  # Batch size\n",
        "    img_size=(224, 224),  # Image size\n",
        "    emotions=emotions,  # Emotions to predict\n",
        "    shuffle=False,  # Do not shuffle validation data\n",
        "    augment=False  # No data augmentation for validation\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLSPJvNbXi-o",
        "outputId": "3fca3866-3eec-42a2-8e11-be20fc5c2d23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample batch shape (images): (32, 224, 224, 3)\n",
            "Sample batch shape (labels): (32, 7)\n"
          ]
        }
      ],
      "source": [
        "# Test the train_generator\n",
        "sample_images, sample_labels = next(iter(train_generator))\n",
        "print(f\"Sample batch shape (images): {sample_images.shape}\")\n",
        "print(f\"Sample batch shape (labels): {sample_labels.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Vv_RJs3hf2A"
      },
      "outputs": [],
      "source": [
        "# Input for movie posters\n",
        "poster_input = Input(shape=(224, 224, 3), name='poster_input')\n",
        "\n",
        "# Load pre-trained VGG16 model without top layers\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_tensor=poster_input)\n",
        "\n",
        "x = Flatten()(base_model.output)  # Flatten the extracted features\n",
        "x = Dense(512, activation='relu')(x)  # Dense layer for further feature processing\n",
        "x = Dropout(0.3)(x)  # Regularization\n",
        "x = Dense(256, activation='relu')(x)  # Additional dense layer for more abstraction\n",
        "x = Dropout(0.3)(x)  # Regularization\n",
        "\n",
        "# Freeze the first few layers to retain pre-trained features\n",
        "for layer in base_model.layers[:10]:  # Freeze the first 10 layers\n",
        "    layer.trainable = False\n",
        "\n",
        "# Output layer for 7 emotions (multi-label classification with sigmoid)\n",
        "output = Dense(len(emotions), activation='sigmoid', name='emotion_output')(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=poster_input, outputs=output)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def multi_label_accuracy(y_true, y_pred):\n",
        "    # Custom metric to calculate multi-label accuracy\n",
        "    y_true = tf.cast(y_true, tf.float32)  # Cast y_true to float32\n",
        "    y_pred = tf.cast(y_pred > 0.5, tf.float32)  # Convert predictions to binary\n",
        "    return tf.reduce_mean(tf.cast(tf.equal(y_true, y_pred), tf.float32))\n",
        "\n",
        "# Define Precision and Recall objects\n",
        "precision_metric = tf.keras.metrics.Precision()\n",
        "recall_metric = tf.keras.metrics.Recall()\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "    # Custom metric to calculate F1 score.\n",
        "    # Reset the state of precision and recall metrics\n",
        "    precision_metric.reset_state()\n",
        "    recall_metric.reset_state()\n",
        "\n",
        "    # Update states with the true and predicted labels\n",
        "    precision_metric.update_state(y_true, y_pred)\n",
        "    recall_metric.update_state(y_true, y_pred)\n",
        "\n",
        "    # Calculate precision and recall\n",
        "    precision = precision_metric.result()  # Result is already a Tensor\n",
        "    recall = recall_metric.result()        # Result is already a Tensor\n",
        "\n",
        "    # Avoid division by zero using Keras epsilon\n",
        "    return 2 * ((precision * recall) / (precision + recall + tf.keras.backend.epsilon()))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=[multi_label_accuracy, f1_score]\n",
        ")\n"
      ],
      "metadata": {
        "id": "Q--BDdHMBZDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data['emotion'] = val_data['Genre'].apply(genres_to_emotions)\n",
        "print(val_data[['Genre', 'emotion']].head())  # Check a few rows\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCS1s5E7srEb",
        "outputId": "54ea87f3-1322-4cfc-d988-014021d06c07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        Genre                emotion\n",
            "52     Action|Sci-Fi|Thriller  [1, 1, 1, 0, 0, 0, 1]\n",
            "27115     Documentary|History  [0, 1, 0, 1, 0, 1, 1]\n",
            "19217                   Drama  [0, 0, 0, 0, 0, 1, 1]\n",
            "4812    Biography|Drama|Music  [0, 0, 0, 1, 1, 1, 1]\n",
            "6830              Crime|Drama  [1, 1, 0, 0, 0, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check a single batch of images and labels\n",
        "train_images, train_labels = next(iter(train_generator))\n",
        "print(\"Sample Batch Labels:\", train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uj2nrtbC7jq3",
        "outputId": "02866310-c50c-4178-e613-22b622e9e913"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Batch Labels: [[1. 1. 1. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 0. 1. 0. 1.]\n",
            " [1. 0. 1. 0. 0. 1. 1.]\n",
            " [1. 1. 1. 0. 0. 1. 1.]\n",
            " [0. 1. 0. 1. 0. 1. 1.]\n",
            " [1. 1. 1. 0. 0. 1. 1.]\n",
            " [1. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 1. 0. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 0. 1. 1. 1.]\n",
            " [1. 1. 1. 0. 1. 0. 1.]\n",
            " [0. 0. 1. 0. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 1. 1.]\n",
            " [0. 0. 1. 0. 1. 1. 1.]\n",
            " [0. 0. 1. 1. 1. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 1.]\n",
            " [0. 0. 1. 0. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 1. 1. 1.]\n",
            " [1. 1. 1. 0. 1. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 1. 1.]\n",
            " [0. 0. 1. 0. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 1. 1.]\n",
            " [1. 1. 1. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1. 1.]\n",
            " [1. 0. 1. 0. 1. 0. 1.]\n",
            " [1. 1. 1. 0. 1. 0. 1.]\n",
            " [1. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 1. 0. 0. 1. 1.]\n",
            " [0. 1. 0. 1. 0. 0. 1.]\n",
            " [1. 1. 1. 0. 0. 1. 1.]\n",
            " [0. 0. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 0. 0. 0. 1. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvYe0iC8Ka3Y",
        "outputId": "e7964105-4d27-405d-93a3-36c96bc04fa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps per epoch: 157\n",
            "Validation steps: 39\n"
          ]
        }
      ],
      "source": [
        "steps_per_epoch = len(train_data) // 32\n",
        "validation_steps = len(val_data) // 32\n",
        "\n",
        "print(f\"Steps per epoch: {(steps_per_epoch)}\")\n",
        "print(f\"Validation steps: {(validation_steps)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01OSj69dRrT3"
      },
      "outputs": [],
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MetricsCallback(Callback):\n",
        "    def __init__(self, validation_data):\n",
        "        super().__init__()\n",
        "        self.validation_data = validation_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        val_images, val_labels = next(iter(self.validation_data))\n",
        "        val_predictions = self.model.predict(val_images)\n",
        "        val_pred_labels = (val_predictions > 0.5).astype(int)\n",
        "\n",
        "        f1 = f1_score(val_labels, val_pred_labels, average='weighted')\n",
        "        precision = precision_score(val_labels, val_pred_labels, average='weighted')\n",
        "        recall = recall_score(val_labels, val_pred_labels, average='weighted')\n",
        "        auc = roc_auc_score(val_labels, val_predictions, average='weighted')\n",
        "\n",
        "        print(f'\\nEpoch {epoch + 1} - F1 Score: {f1:.4f} - Precision: {precision:.4f} - Recall: {recall:.4f} - AUC: {auc:.4f}')"
      ],
      "metadata": {
        "id": "njbjAG6ULdff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_images, val_labels = next(iter(val_generator))\n",
        "metrics_callback = MetricsCallback(validation_data=(val_images, val_labels))"
      ],
      "metadata": {
        "id": "ub2GSPZdbl21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8P9Pxujhqny"
      },
      "outputs": [],
      "source": [
        "# Model Checkpoint\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath='best_model.keras',  # File path to save the model\n",
        "    monitor='val_f1_score',  # Metric to monitor\n",
        "    mode='max',              # Save based on the highest value of the metric\n",
        "    save_best_only=True,     # Save only the best model\n",
        "    verbose=1\n",
        ")\n",
        "# Instantiate the MetricsCallback\n",
        "metrics_callback = MetricsCallback(validation_data=(val_generator))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=11,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=[checkpoint],\n",
        "    class_weight=class_weights_dict,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKKW3DCGvj0c",
        "outputId": "1c5ede1d-a37f-48c3-ce69-f0050148190d"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/11\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35s/step - f1_score: 0.6311 - loss: 0.9771 - multi_label_accuracy: 0.6133 \n",
            "Epoch 1: val_f1_score improved from -inf to 0.69159, saving model to best_model.keras\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6672s\u001b[0m 41s/step - f1_score: 0.6313 - loss: 0.9754 - multi_label_accuracy: 0.6134 - val_f1_score: 0.6916 - val_loss: 0.6243 - val_multi_label_accuracy: 0.6593\n",
            "Epoch 2/11\n",
            "\u001b[1m  1/157\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:52:29\u001b[0m 43s/step - f1_score: 0.6840 - loss: 0.6122 - multi_label_accuracy: 0.6741"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.11/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2: val_f1_score did not improve from 0.69159\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 48ms/step - f1_score: 0.3442 - loss: 0.6122 - multi_label_accuracy: 0.3392 - val_f1_score: 0.3217 - val_loss: 0.6459 - val_multi_label_accuracy: 0.3048\n",
            "Epoch 3/11\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35s/step - f1_score: 0.6792 - loss: 0.6332 - multi_label_accuracy: 0.6585 \n",
            "Epoch 3: val_f1_score improved from 0.69159 to 0.70312, saving model to best_model.keras\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6170s\u001b[0m 39s/step - f1_score: 0.6793 - loss: 0.6332 - multi_label_accuracy: 0.6585 - val_f1_score: 0.7031 - val_loss: 0.6123 - val_multi_label_accuracy: 0.6755\n",
            "Epoch 4/11\n",
            "\u001b[1m  1/157\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45:00\u001b[0m 40s/step - f1_score: 0.7347 - loss: 0.6205 - multi_label_accuracy: 0.7098\n",
            "Epoch 4: val_f1_score did not improve from 0.70312\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 60ms/step - f1_score: 0.3697 - loss: 0.6205 - multi_label_accuracy: 0.3572 - val_f1_score: 0.3304 - val_loss: 0.6385 - val_multi_label_accuracy: 0.3143\n",
            "Epoch 5/11\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34s/step - f1_score: 0.6915 - loss: 0.6288 - multi_label_accuracy: 0.6661 \n",
            "Epoch 5: val_f1_score improved from 0.70312 to 0.70619, saving model to best_model.keras\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6127s\u001b[0m 39s/step - f1_score: 0.6916 - loss: 0.6287 - multi_label_accuracy: 0.6661 - val_f1_score: 0.7062 - val_loss: 0.6099 - val_multi_label_accuracy: 0.6724\n",
            "Epoch 6/11\n",
            "\u001b[1m  1/157\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45:04\u001b[0m 40s/step - f1_score: 0.7040 - loss: 0.6265 - multi_label_accuracy: 0.6696\n",
            "Epoch 6: val_f1_score did not improve from 0.70619\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 52ms/step - f1_score: 0.3542 - loss: 0.6265 - multi_label_accuracy: 0.3370 - val_f1_score: 0.3534 - val_loss: 0.6297 - val_multi_label_accuracy: 0.3381\n",
            "Epoch 7/11\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35s/step - f1_score: 0.7022 - loss: 0.6171 - multi_label_accuracy: 0.6795 \n",
            "Epoch 7: val_f1_score improved from 0.70619 to 0.70933, saving model to best_model.keras\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6172s\u001b[0m 39s/step - f1_score: 0.7022 - loss: 0.6171 - multi_label_accuracy: 0.6795 - val_f1_score: 0.7093 - val_loss: 0.6001 - val_multi_label_accuracy: 0.6850\n",
            "Epoch 8/11\n",
            "\u001b[1m  1/157\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:27:14\u001b[0m 34s/step - f1_score: 0.6606 - loss: 0.6408 - multi_label_accuracy: 0.6652\n",
            "Epoch 8: val_f1_score did not improve from 0.70933\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 58ms/step - f1_score: 0.3324 - loss: 0.6408 - multi_label_accuracy: 0.3347 - val_f1_score: 0.3421 - val_loss: 0.6345 - val_multi_label_accuracy: 0.3286\n",
            "Epoch 9/11\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35s/step - f1_score: 0.7012 - loss: 0.6070 - multi_label_accuracy: 0.6843 \n",
            "Epoch 9: val_f1_score did not improve from 0.70933\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6165s\u001b[0m 39s/step - f1_score: 0.7012 - loss: 0.6070 - multi_label_accuracy: 0.6842 - val_f1_score: 0.7054 - val_loss: 0.6018 - val_multi_label_accuracy: 0.6819\n",
            "Epoch 10/11\n",
            "\u001b[1m  1/157\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:27:22\u001b[0m 34s/step - f1_score: 0.7124 - loss: 0.5552 - multi_label_accuracy: 0.7009\n",
            "Epoch 10: val_f1_score did not improve from 0.70933\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 357ms/step - f1_score: 0.3585 - loss: 0.5552 - multi_label_accuracy: 0.3527 - val_f1_score: 0.3364 - val_loss: 0.6312 - val_multi_label_accuracy: 0.3286\n",
            "Epoch 11/11\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34s/step - f1_score: 0.7014 - loss: 0.6042 - multi_label_accuracy: 0.6867 \n",
            "Epoch 11: val_f1_score did not improve from 0.70933\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6124s\u001b[0m 39s/step - f1_score: 0.7015 - loss: 0.6042 - multi_label_accuracy: 0.6867 - val_f1_score: 0.6987 - val_loss: 0.6073 - val_multi_label_accuracy: 0.6837\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7954f8d66c10>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8gAUs3c_vkB"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/movie_emotion_model_fin.keras')  # Save to Drive"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBkcwVNPg+ediLt4sL6lkE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}